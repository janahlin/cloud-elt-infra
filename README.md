# Cloud ELT Infrastructure

This repository provides Terraform configurations and automation scripts for deploying an ELT pipeline infrastructure on **OCI** and **Azure**. It includes:
- **Databricks** for data processing
- **Apache Airflow** (for OCI) or **Azure Data Factory** (for Azure) for workflow orchestration
- **Python ingestion scripts** for fetching data from external sources
- **dbt models** for transformation

## ðŸ“Œ Repository Structure
```
/terraform
   â”œâ”€â”€ /modules
   â”‚    â”œâ”€â”€ airflow/
   â”‚    â”œâ”€â”€ data_factory/
   â”‚    â”œâ”€â”€ databricks/
   â”‚    â”œâ”€â”€ networking/
   â”‚    â”œâ”€â”€ storage/
   â”‚    â””â”€â”€ compute/
   â”œâ”€â”€ /environments
   â”‚    â”œâ”€â”€ oci/
   â”‚    â”œâ”€â”€ azure/
   â”œâ”€â”€ main.tf
   â”œâ”€â”€ variables.tf
   â”œâ”€â”€ outputs.tf
/ingestion
   â”œâ”€â”€ api_ingestion.py
   â”œâ”€â”€ requirements.txt
/dbt_project
   â”œâ”€â”€ dbt_project.yml
   â”œâ”€â”€ models/
/workflows
   â”œâ”€â”€ airflow_dag.py
   â”œâ”€â”€ data_factory_pipeline.json
README.md
```

## ðŸš€ Deployment Instructions

1. Clone the repository:
   ```sh
   git clone https://github.com/YOUR_USERNAME/cloud-elt-infra.git
   ```

2. Install Terraform and authenticate to your cloud provider.

3. Run Terraform initialization:
   ```sh
   terraform init
   ```

4. Apply Terraform interactively:
   ```sh
   terraform apply
   ```
   You will be prompted to select:
   - **Cloud Provider** (`oci` or `azure`)
   - **Deployment Environment** (`dev`, `staging`, `production`)

5. The ELT tool is automatically chosen based on the cloud provider:
   - If **Azure** is selected â†’ **Azure Data Factory** is used
   - If **OCI** is selected â†’ **Apache Airflow** is used

6. Run ingestion scripts and dbt transformations as needed.

## ðŸ”§ Configuration

Modify `terraform.tfvars` (optional) if you want to **predefine the values** instead of interactive input.

## ðŸ“œ License

This project is licensed under the MIT License.
