# Cloud ELT Infrastructure

This repository provides Terraform configurations and automation scripts for deploying an ELT pipeline infrastructure on **OCI** and **Azure**. It includes:
- **Databricks** for data processing
- **Apache Airflow** or **Azure Data Factory** for workflow orchestration
- **Python ingestion scripts** for fetching data from external sources
- **dbt models** for transformation

## ðŸ“Œ Repository Structure
```
/terraform
   â”œâ”€â”€ /modules
   â”‚    â”œâ”€â”€ airflow/
   â”‚    â”œâ”€â”€ data_factory/
   â”‚    â”œâ”€â”€ databricks/
   â”‚    â”œâ”€â”€ networking/
   â”‚    â”œâ”€â”€ storage/
   â”‚    â””â”€â”€ compute/
   â”œâ”€â”€ /environments
   â”‚    â”œâ”€â”€ oci/
   â”‚    â”œâ”€â”€ azure/
   â”œâ”€â”€ main.tf
   â”œâ”€â”€ variables.tf
   â”œâ”€â”€ outputs.tf
/ingestion
   â”œâ”€â”€ api_ingestion.py
   â”œâ”€â”€ requirements.txt
/dbt_project
   â”œâ”€â”€ dbt_project.yml
   â”œâ”€â”€ models/
/workflows
   â”œâ”€â”€ airflow_dag.py
   â”œâ”€â”€ data_factory_pipeline.json
README.md
```

## ðŸš€ Deployment Instructions

1. Clone the repository:
   ```sh
   git clone https://github.com/janahlin/cloud-elt-infra.git
   ```

2. Install Terraform and authenticate to your cloud provider.

3. Choose the deployment environment (OCI or Azure) and configure `terraform.tfvars`.

4. Apply Terraform:
   ```sh
   terraform init
   terraform apply -var-file=terraform.tfvars
   ```

5. Run ingestion scripts and dbt transformations as needed.

## ðŸ”§ Configuration

Modify `terraform.tfvars` based on your cloud provider and ELT tool selection.

- To use **Airflow**, set `use_airflow = true`
- To use **Azure Data Factory**, set `use_airflow = false`

## ðŸ“œ License

This project is licensed under the MIT License.
